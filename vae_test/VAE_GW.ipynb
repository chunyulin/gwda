{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy      ver.  1.15.4\n",
      "Numba      ver.  0.41.0\n",
      "H5Py       ver.  2.7.1\n",
      "SKLearn    ver.  0.19.2\n",
      "TensorFlow ver.  1.12.0\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10503346741766320565\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7588364685598657267\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14091881874487066601\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 134545408\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9068322182177462645\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5769592832\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10631235674830832572\n",
      "physical_device_desc: \"device: 1, name: GeForce GTX 1060 6GB, pci bus id: 0000:84:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "### Project: Autoencoder with hidden layer constrained\n",
    "############################################################\n",
    "\n",
    "#### Prepare env\n",
    "from __future__ import print_function\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import numba\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "print (\"Numpy      ver. \", np.__version__)\n",
    "print (\"Numba      ver. \", numba.__version__)  ##  optimize numpy?!?\n",
    "print (\"H5Py       ver. \", h5.__version__)\n",
    "print (\"SKLearn    ver. \", sklearn.__version__)\n",
    "print (\"TensorFlow ver. \", tf.__version__)\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('agg')             ## Need for CMD\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load waveform data\n",
    "\n",
    "H5_FILE=\"white_h_8192_dm2.h5\"\n",
    "RATE=8192\n",
    "H5_FILE=\"white_h_4096_dm2.h5\"\n",
    "RATE=4096\n",
    "\n",
    "#!wget http://grqc.ncts.ncku.edu.tw/~lincy/GWDA/white_h_4096_dm2.h5\n",
    "#!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of whiten waveform for each set:  685\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Now, visualize the dataset \n",
    "\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f = h5.File(H5_FILE,'r')\n",
    "m1t = f['train_m1']\n",
    "m2t = f['train_m2']\n",
    "m1v = f['val_m1']\n",
    "m2v = f['val_m2']\n",
    "m1s = f['test_m1']\n",
    "m2s = f['test_m2']\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(m2t, m1t, 'r.', markersize=2, label=\"Training\")\n",
    "plt.plot(m2v, m1v, 'b.', markersize=2, label=\"Validation\")\n",
    "plt.plot(m2s, m1s, 'g.', markersize=2, label=\"Test\")\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "plt.savefig(\"VAE_tpl.png\")\n",
    "\n",
    "print (\"# of whiten waveform for each set: \", len(f['train_hp']))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Prepare data: extract, transform, load (ETL)\n",
    "###\n",
    "import time\n",
    "#from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "_NOISE_COPY_ = 1\n",
    "class GWInject():\n",
    "    def _add_noise(self, tag, A, nc):\n",
    "        var = self.f[tag]\n",
    "        NX = len(var)\n",
    "        NN = nc * NX\n",
    "        noise = np.random.normal(0,1,(NN,self.srate))    \n",
    "        X     = np.random.normal(0,1,(NX,self.srate))  + A * var[:NX,:]      \n",
    "        if self.plot:\n",
    "            plt.figure(figsize=(18,6))\n",
    "            for i in range(len(X)):\n",
    "                plt.subplot(3,5,i+1)         \n",
    "                plt.plot(X[i,:])\n",
    "                plt.plot(A * var[i,:])\n",
    "                #plt.title(\" )\n",
    "                if (i > 13): break\n",
    "            plt.show()\n",
    "\n",
    "        X = np.vstack( (noise, X )  ).astype(np.float32)\n",
    "        Y = np.array([0]*NN + [1]*NX).astype(np.float32).reshape(-1,1)\n",
    "        #return shuffle(X, Y, random_state=0)\n",
    "        return X, Y\n",
    "    \n",
    "    def __init__(self, fname, plot=0):\n",
    "        self.fname = fname\n",
    "        self.plot = plot\n",
    "        self.f = h5.File(fname, \"r\")\n",
    "        self.srate = self.f.attrs.get('srate')   ##4096/ 8192\n",
    "        print(self.srate, self.f.attrs.get('merger_idx'))\n",
    "        \n",
    "    def __exit__(self):\n",
    "        self.f.close()\n",
    "        \n",
    "    def get_train_set(self, A=1.0, nc = _NOISE_COPY_):\n",
    "        X, Y = self._add_noise('/train_hp', A, nc = nc)\n",
    "        return X, Y\n",
    "    def get_val_set(self, A=1.0, nc = _NOISE_COPY_):\n",
    "        X, Y = self._add_noise('/val_hp', A, nc = nc)\n",
    "        return X, Y\n",
    "    def get_test_set(self, A=1.0):\n",
    "        X, Y = self._add_noise('/test_hp', A, nc = _NOISE_COPY_)\n",
    "        return X, Y\n",
    "\n",
    "      \n",
    "    def getdata(self, tag='/train', A=1.0):\n",
    "        X1 = A*np.array(self.f[tag+'_hp'])  #.astype(np.float32)\n",
    "        X2 = A*np.array(self.f[tag+'_hc'])  #.astype(np.float32)\n",
    "        Y  = np.vstack(( self.f[tag+'_m1'],self.f[tag+'_m2'] )).astype(np.float32)\n",
    "        \n",
    "        if self.plot:\n",
    "            plt.figure(figsize=(18,6))\n",
    "            for i in range(len(X1)):\n",
    "                plt.subplot(3,5,i+1)         \n",
    "                plt.plot(X1[i,:])\n",
    "                plt.title(\"m=(%.1f, %.1f)\"%(Y[0,i],Y[1,i]))\n",
    "                plt.xticks([])\n",
    "                if (i > 13): break\n",
    "            plt.show()\n",
    "            \n",
    "        return X1,X2,np.transpose(Y)\n",
    "        #return np.hstack((X1, X2)), Y\n",
    "    \n",
    "#tmp = GWInject(H5_FILE, plot=0)\n",
    "AMP = 0.7\n",
    "#X,Y,_ = tmp.getdata('/train', A=AMP)  \n",
    "#print(X.shape)\n",
    "#print(X.shape)\n",
    "#tmp.__exit__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main autoencoder:  See https://www.ycc.idv.tw/tensorflow-tutorial_4.html\n",
    "import random\n",
    "\n",
    "class Autoencoder(object):\n",
    "    def __init__(self,n_features,learning_rate=0.5,n_hidden=[1024,512,256,2],alpha=0.0):\n",
    "\n",
    "        assert n_hidden[-1]==2, \"!!! Make sure n_hidden[-1]==2\"\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "\n",
    "        self.graph = tf.Graph() # initialize new grap\n",
    "        self.build(n_features,learning_rate,n_hidden,alpha) # building graph\n",
    "        self.sess = tf.Session(graph=self.graph) # create session by the graph \n",
    "        \n",
    "        #summary_writer.add_graph(self.graph)\n",
    "\n",
    "            \n",
    "    def build(self,n_features,learning_rate,n_hidden,alpha):\n",
    "        with self.graph.as_default():\n",
    "            ### Input\n",
    "            self.train_features = tf.placeholder(tf.float32, shape=(None,n_features))\n",
    "            self.train_targets  = tf.placeholder(tf.float32, shape=(None,n_hidden[-1]))   ### for \"constraint\" hidden\n",
    "            self.latent         = tf.placeholder(tf.float32, shape=(None, n_hidden[-1]))\n",
    "\n",
    "            ### Optimalization\n",
    "            # build neurel network structure and get their predictions and loss\n",
    "            self.y_, self.original_loss, _ = self.structure(\n",
    "                                               X=self.train_features,\n",
    "                                               Y=self.train_targets, n_hidden=n_hidden )\n",
    "\n",
    "            # regularization loss\n",
    "            # weight elimination L2 regularizer\n",
    "            self.regularizer = tf.reduce_sum([tf.reduce_sum(\n",
    "                        tf.pow(w,2)/(1+tf.pow(w,2))) for w in self.weights.values()]) \\\n",
    "                    / tf.reduce_sum(\n",
    "                     [tf.size(w,out_type=tf.float32) for w in self.weights.values()])\n",
    "\n",
    "            # total loss\n",
    "            self.loss = self.original_loss + alpha * self.regularizer\n",
    "\n",
    "            # define training operation\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "            self.train_op = self.optimizer.minimize(self.loss)\n",
    "\n",
    "            ### Prediction\n",
    "            self.new_features = tf.placeholder(tf.float32, shape=(None,n_features))\n",
    "            self.new_targets  = tf.placeholder(tf.float32, shape=(None,n_hidden[-1]))\n",
    "            self.new_y_, self.new_original_loss, self.new_encoder = self.structure(\n",
    "                                                          X=self.new_features,\n",
    "                                                          Y=self.new_targets, n_hidden=n_hidden)  \n",
    "            self.new_loss = self.new_original_loss + alpha * self.regularizer\n",
    "\n",
    "            ### genwf\n",
    "            \n",
    "            \n",
    "            ### Initialization\n",
    "            self.init_op = tf.global_variables_initializer()  \n",
    "\n",
    "    def genwf(self, latent):\n",
    "        activation = tf.math.atan\n",
    "        decoder = self.getDenseLayer(self.latent,\n",
    "                                     self.weights['decode1'],\n",
    "                                     self.biases['decode1'],\n",
    "                                     activation=activation)\n",
    "        for i in range(1,len(self.n_hidden)):\n",
    "            decoder = self.getDenseLayer(decoder,\n",
    "                        self.weights['decode{}'.format(i+1)],\n",
    "                        self.biases['decode{}'.format(i+1)],\n",
    "                        activation=activation) \n",
    "        return self.sess.run(decoder, feed_dict={self.latent : latent})\n",
    "      \n",
    "    def generator(self, latent):\n",
    "        activation = tf.math.atan\n",
    "        decoder = self.getDenseLayer(latent,\n",
    "                                     self.weights['decode1'],\n",
    "                                     self.biases['decode1'],\n",
    "                                     activation=activation)\n",
    "\n",
    "        for i in range(1,len(self.n_hidden)):\n",
    "            decoder = self.getDenseLayer(decoder,\n",
    "                        self.weights['decode{}'.format(i+1)],\n",
    "                        self.biases['decode{}'.format(i+1)],\n",
    "                        activation=activation) \n",
    "        return decoder\n",
    "      \n",
    "    def structure(self, X, Y, n_hidden):\n",
    "        ### Variable\n",
    "        if (not self.weights) and (not self.biases):\n",
    "            self.weights = {}\n",
    "            self.biases  = {}\n",
    "\n",
    "            n_encoder = [self.n_features] + n_hidden\n",
    "            for i,n in enumerate(n_encoder[:-1]):\n",
    "                #print (\"e\",i+1,n)\n",
    "                self.weights['encode{}'.format(i+1)] = \\\n",
    "                    tf.Variable(tf.truncated_normal(\n",
    "                        shape=(n,n_encoder[i+1]),stddev=0.1),dtype=tf.float32)\n",
    "                self.biases['encode{}'.format(i+1)] = \\\n",
    "                    tf.Variable(tf.zeros( shape=(n_encoder[i+1]) ),dtype=tf.float32)\n",
    "\n",
    "            #del list\n",
    "            n_decoder = list(reversed(n_hidden))+[self.n_features]\n",
    "            for i,n in enumerate(n_decoder[:-1]):\n",
    "                #print (\"d\", i+1,n)\n",
    "                self.weights['decode{}'.format(i+1)] = \\\n",
    "                    tf.Variable(tf.truncated_normal(\n",
    "                        shape=(n,n_decoder[i+1]),stddev=0.1),dtype=tf.float32)\n",
    "                self.biases['decode{}'.format(i+1)] = \\\n",
    "                    tf.Variable(tf.zeros( shape=(n_decoder[i+1]) ),dtype=tf.float32)                    \n",
    "\n",
    " \n",
    "        activation = tf.math.atan\n",
    "        encoder = self.getDenseLayer(X,\n",
    "                                     self.weights['encode1'],\n",
    "                                     self.biases['encode1'],\n",
    "                                     activation=activation)\n",
    "        for i in range(1, len(self.n_hidden)-1):\n",
    "            encoder = self.getDenseLayer(encoder,\n",
    "                        self.weights['encode{}'.format(i+1)],\n",
    "                        self.biases['encode{}'.format(i+1)],\n",
    "                        activation=activation)\n",
    "        encoder = self.getDenseLayer(encoder,\n",
    "                    self.weights['encode{}'.format(len(self.n_hidden))],\n",
    "                    self.biases['encode{}'.format(len(self.n_hidden))],\n",
    "                    activation=tf.nn.relu)\n",
    "\n",
    "        decoder = self.generator(encoder)\n",
    "\n",
    "        #loss = tf.nn.sigmoid_cross_entropy_with_logits(X, decoder)  +  tf.reduce_mean(tf.pow(Y- encoder, 2))\n",
    "        loss = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=decoder) )\n",
    "        #loss = tf.reduce_mean(tf.pow(X - decoder, 2))  +  tf.reduce_mean(tf.pow(Y- encoder, 2))\n",
    "\n",
    "        return (decoder,loss,encoder)\n",
    "\n",
    "    def getDenseLayer(self,input_layer,weight,bias,activation=None):\n",
    "        x = tf.add(tf.matmul(input_layer,weight),bias)\n",
    "        if activation:\n",
    "            x = activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def fit(self,X,Y,epochs=10,validation_data=None,test_data=None,batch_size=None):\n",
    "        X = self._check_array(X)\n",
    "        Y = self._check_array(Y)\n",
    "\n",
    "        N = X.shape[0]\n",
    "        random.seed(9000)\n",
    "        if not batch_size: batch_size=N\n",
    "\n",
    "        self.sess.run(self.init_op)\n",
    "        start_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            #if epoch%100==0:   print(\"Epoch %2d/%2d: \"%(epoch+1,epochs))\n",
    "\n",
    "            # mini-batch gradient descent\n",
    "            index = [i for i in range(N)]   #random.shuffle(index)\n",
    "            while len(index)>0:\n",
    "                index_size = len(index)\n",
    "                batch_index = [index.pop() for _ in range(min(batch_size,index_size))]\n",
    "                merged = tf.summary.merge_all()\n",
    "\n",
    "                feed_dict = {self.train_features: X[batch_index,:],\n",
    "                             self.train_targets:  Y[batch_index,:]}\n",
    "                _, loss = self.sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
    "                #_, loss, merged0 = self.sess.run([self.train_op, self.loss, merged], feed_dict=feed_dict)\n",
    "\n",
    "                ##if epoch%100==0: print(\"[%d/%d] loss = %9.4f     \" % ( N-len(index), N, loss ), end='\\r')\n",
    "                ##summary_writer.add_summary(merged0, epoch)\n",
    "\n",
    "            # evaluate at the end of this epoch\n",
    "            val_loss = 0\n",
    "            if validation_data is not None: val_loss = self.evaluate(validation_data[0],validation_data[1])\n",
    "\n",
    "            train_loss = self.evaluate(X,Y)\n",
    "            if epoch%20==0: print(\"[%5d] %5ds tloss = %9.4f   vloss = %9.4f\" % ( epoch, (time.time()-start_time), train_loss, val_loss ))\n",
    "\n",
    "        if test_data is not None:\n",
    "            test_loss = self.evaluate(test_data[0],test_data[1])\n",
    "            print(\"test_loss = %9.4f\" % (test_loss))\n",
    "\n",
    "    #def encode(self,X):\n",
    "    #    X = self._check_array(X)\n",
    "    #    return self.sess.run(self.new_encoder, feed_dict={self.new_features: X})\n",
    "\n",
    "    def predict(self,X):\n",
    "        X = self._check_array(X)\n",
    "        return self.sess.run(self.new_y_, feed_dict={self.new_features: X})\n",
    "\n",
    "    def evaluate(self,X,Y):\n",
    "        X = self._check_array(X)\n",
    "        return self.sess.run(self.new_loss, feed_dict={self.new_features: X,\n",
    "                                                       self.new_targets: Y})\n",
    "\n",
    "    def _check_array(self,ndarray):\n",
    "        ndarray = np.array(ndarray)\n",
    "        if len(ndarray.shape)==1: ndarray = np.reshape(ndarray,(1,ndarray.shape[0]))\n",
    "        return ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096 0.66\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [2,128] and type float\n\t [[node Variable_10/Adam/Initializer/zeros (defined at <ipython-input-7-5b97dc3c177e>:46)  = Const[_class=[\"loc:@Variable_10/Assign\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [2,128] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op u'Variable_10/Adam/Initializer/zeros', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/lib64/python2.7/site-packages/tornado/ioloop.py\", line 1065, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-f84f6b5a0749>\", line 9, in <module>\n    alpha=0.001\n  File \"<ipython-input-7-5b97dc3c177e>\", line 15, in __init__\n    self.build(n_features,learning_rate,n_hidden,alpha) # building graph\n  File \"<ipython-input-7-5b97dc3c177e>\", line 46, in build\n    self.train_op = self.optimizer.minimize(self.loss)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 410, in minimize\n    name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 593, in apply_gradients\n    self._create_slots(var_list)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/adam.py\", line 135, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 1139, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 183, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 157, in create_slot_with_initializer\n    dtype)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1487, in get_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1237, in get_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 540, in get_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 922, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 1437, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 896, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py\", line 101, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1551, in zeros\n    output = _constant_if_small(zero, shape, dtype, name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1509, in _constant_if_small\n    return constant(value, shape=shape, dtype=dtype, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py\", line 214, in constant\n    name=name).outputs[0]\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [2,128] and type float\n\t [[node Variable_10/Adam/Initializer/zeros (defined at <ipython-input-7-5b97dc3c177e>:46)  = Const[_class=[\"loc:@Variable_10/Assign\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [2,128] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f84f6b5a0749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m            \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m            \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m           )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5b97dc3c177e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, epochs, validation_data, test_data, batch_size)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [2,128] and type float\n\t [[node Variable_10/Adam/Initializer/zeros (defined at <ipython-input-7-5b97dc3c177e>:46)  = Const[_class=[\"loc:@Variable_10/Assign\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [2,128] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op u'Variable_10/Adam/Initializer/zeros', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/lib64/python2.7/site-packages/tornado/ioloop.py\", line 1065, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-f84f6b5a0749>\", line 9, in <module>\n    alpha=0.001\n  File \"<ipython-input-7-5b97dc3c177e>\", line 15, in __init__\n    self.build(n_features,learning_rate,n_hidden,alpha) # building graph\n  File \"<ipython-input-7-5b97dc3c177e>\", line 46, in build\n    self.train_op = self.optimizer.minimize(self.loss)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 410, in minimize\n    name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 593, in apply_gradients\n    self._create_slots(var_list)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/adam.py\", line 135, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 1139, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 183, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 157, in create_slot_with_initializer\n    dtype)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1487, in get_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1237, in get_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 540, in get_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 922, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 1437, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 896, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py\", line 101, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1551, in zeros\n    output = _constant_if_small(zero, shape, dtype, name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1509, in _constant_if_small\n    return constant(value, shape=shape, dtype=dtype, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py\", line 214, in constant\n    name=name).outputs[0]\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [2,128] and type float\n\t [[node Variable_10/Adam/Initializer/zeros (defined at <ipython-input-7-5b97dc3c177e>:46)  = Const[_class=[\"loc:@Variable_10/Assign\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [2,128] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "### Training \n",
    "\n",
    "model_1 = Autoencoder( n_features = RATE,\n",
    "                       learning_rate = 0.004,\n",
    "                       #n_hidden=[4096, 2048, 512, 256, 128, 32, 16, 8, 2],\n",
    "                       #n_hidden=[2048, 512, 256, 128, 2],  ### noise in inspiral region   0.001\n",
    "                       n_hidden=[2048, 512, 256, 128, 2],\n",
    "                       ##n_hidden=[2048, 1024, 512, 256, 128, 64], ## add 1024 will spoil the output###  64 latent OK   \n",
    "                       alpha=0.001\n",
    "                     )\n",
    "\n",
    "tmp = GWInject(H5_FILE, plot=0)\n",
    "Xt,Xt2,Yt = tmp.getdata('/train', A=AMP)  \n",
    "Xv,Xv2,Yv = tmp.getdata('/val', A=AMP)  \n",
    "Xs,Xs2,Ys = tmp.getdata('/test', A=AMP)  \n",
    "#Xt=np.hstack((Xt1,Xt2))\n",
    "#Xv=np.hstack((Xv1,Xv2))\n",
    "#Xs=np.hstack((Xs1,Xs2))\n",
    "\n",
    "model_1.fit(X=Xt, Y=Yt,\n",
    "           epochs=3000,\n",
    "           validation_data=(Xv, Yv),\n",
    "           test_data=(Xs, Ys),\n",
    "           batch_size = 128\n",
    "          )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Test if it can produce an input GW signal\n",
    "### \n",
    "for i in range(10,11):\n",
    "    plt.figure()\n",
    "    w0 = Xt[i]\n",
    "    w1 = model_1.predict(w0)\n",
    "    print (Yt[i,0],Yt[i,1])\n",
    "    print (w1)\n",
    "    print (w0.max(),w0.min())\n",
    "    print (w1.max(),w1.min())\n",
    "    plt.plot(w1[0])\n",
    "    plt.plot(w0)\n",
    "    #plt.show()\n",
    "    plt.savefig(\"VAE_test1.png\")\n",
    "\n",
    "    plt.figure()    \n",
    "    plt.plot(w1[0]-w0)\n",
    "    plt.savefig(\"VAE_test1diff.png\")\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Test if it can produce many input GW signals\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "\n",
    "ranidx = random.sample(range(len(Xt)), 30)   ## test randomly sample\n",
    "w0 = Xt[ranidx]\n",
    "w1 = model_1.predict(w0)\n",
    "\n",
    "for i in range(len(ranidx)):\n",
    "    plt.subplot(6,5,i+1)         \n",
    "    plt.title(\"m=(%.1f, %.1f)\"%(Yt[ranidx[i],0],Yt[ranidx[i],1]))\n",
    "    plt.plot(w0[i]-w1[i])\n",
    "    plt.xticks([])\n",
    "    \n",
    "    if (i > 25): break\n",
    "plt.savefig(\"VAE_testdiff.png\")\n",
    "\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Generate from latent variables\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "\n",
    "ranidx = random.sample(range(len(Xt)), 16)   ## test randomly sample\n",
    "w0 = Xt[ranidx]\n",
    "w1 = model_1.predict(w0)\n",
    "wg = model_1.genwf(Yt[ranidx])\n",
    "for i in range(len(ranidx)):\n",
    "    plt.subplot(6,5,i+1)         \n",
    "    plt.title(\"m=(%.1f, %.1f)\"%(Yt[ranidx[i],0],Yt[ranidx[i],1]))\n",
    "    plt.plot(wg[i])\n",
    "    #plt.plot(w1[i]-wg[i])\n",
    "    plt.xticks([])\n",
    "    \n",
    "    if (i > 25): break\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(\"VAE_gen.png\")\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
