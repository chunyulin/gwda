{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Generate whiten data \"whiten_h_xxxx.h5\" from \"bbh...\"\n",
    "###\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "import pycbc.noise\n",
    "import pycbc.psd\n",
    "import pycbc.waveform\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.mlab as mlab\n",
    "import numpy as np\n",
    "import seaborn\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, filtfilt, iirdesign, zpk2tf, freqz\n",
    "\n",
    "#\n",
    "# Define PSD\n",
    "#\n",
    "def aLIGO_PSD(flow = 10.0, FMAX=8000, delta_f = 1./16., SEED=None):\n",
    "    flen = int(FMAX / delta_f) + 1\n",
    "    psd = pycbc.psd.aLIGOZeroDetHighPower(flen, delta_f, flow)\n",
    "    return psd\n",
    "\n",
    "def aLIGO_PSD_inp(flow = 10.0, FMAX=8000, delta_f = 1./16., SEED=None):\n",
    "    flen = int(FMAX / delta_f) + 1\n",
    "    psd = pycbc.psd.aLIGOZeroDetHighPower(flen, delta_f, flow)\n",
    "    #psd = pycbc.psd.analytical.aLIGOZeroDetHighPower(flen, delta_f, flow)\n",
    "    freqs = psd.sample_frequencies\n",
    "        \n",
    "    ## have to tweak the data to avoid 1/0 problem\n",
    "    sel = np.where( psd.data<1.e-60 )\n",
    "    psd.data[sel] = 1\n",
    "        \n",
    "    psd_interp = interp1d(freqs, psd)\n",
    "\n",
    "    if 0:\n",
    "        plt.loglog(freqs, np.sqrt(psd) )\n",
    "        plt.show()\n",
    "    \n",
    "    return psd_interp\n",
    "\n",
    "def LIGO_PSD_inp(FMAX=8192, delta_f = 1./16.):\n",
    "    flen = int(FMAX / delta_f) + 1\n",
    "    freqs = np.linspace(0,FMAX,flen)\n",
    "    Pxx = (1.e-22*(18./(0.1+freqs))**2)**2+0.7e-23**2+((freqs/2000.)*4.e-23)**2\n",
    "    \n",
    "    psd_interp = interp1d(freqs, Pxx)\n",
    "    return psd_interp\n",
    "\n",
    "def PSD_from(timeseries, RATE=8192, alpha=0.1):\n",
    "    ## calculate the PSD of data\n",
    "    NFFT=RATE     \n",
    "    ss_psd, f_ss = mlab.psd(timeseries, Fs = RATE, NFFT = NFFT, noverlap=NFFT/8, window=signal.tukey(NFFT, alpha=alpha) )\n",
    "    psd_inp = interp1d(f_ss, ss_psd)\n",
    "    \n",
    "    return f_ss, psd_inp\n",
    "\n",
    "\n",
    "from scipy.signal import butter, filtfilt, iirdesign, zpk2tf, freqz\n",
    "\n",
    "def whiten(strain, interp_psd, dt, bp=0):\n",
    "    Nt = len(strain)\n",
    "    f = np.fft.rfftfreq(Nt, dt)\n",
    "    #print len(f), f\n",
    "    \n",
    "    #dwindow = 1  ##signal.tukey(Nt, alpha=alpha)\n",
    "    hf = np.fft.rfft(strain)\n",
    "    \n",
    "    norm = np.sqrt(dt*2)\n",
    "    white_hf = hf / np.sqrt(interp_psd(f)) * norm\n",
    "    white_ht = np.fft.irfft(white_hf, n=Nt)\n",
    "    \n",
    "    if bp:\n",
    "        ## Bandpassing with 4th-order Butterworth D/A filter\n",
    "        fband = [10.,800.]\n",
    "        bb, ab = butter(4, [fband[0]*2./RATE, fband[1]*2./RATE], btype='band')\n",
    "        normalization = np.sqrt((fband[1]-fband[0])/(RATE/2.0))\n",
    "        white_ht = filtfilt(bb, ab, white_ht) / normalization\n",
    "        \n",
    "        if 0:  ## TODO\n",
    "            plt.figure()\n",
    "            w, h = signal.freqs(bb, ab)\n",
    "            plt.plot(w, 20 * np.log10(abs(h)))\n",
    "            plt.xscale('log')\n",
    "            plt.title('Butterworth filter frequency response')\n",
    "            plt.xlabel('Frequency [radians / second]')\n",
    "            plt.ylabel('Amplitude [dB]')\n",
    "            plt.margins(0, 0.1)\n",
    "            plt.grid(which='both', axis='both')\n",
    "            plt.axvline(100, color='green') # cutoff frequency\n",
    "            plt.show()\n",
    "\n",
    "    return white_ht\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('process ...', 19, 61, 0, 241)\n",
      "10162\n",
      "('process ...', 57, 77, 100, 629)\n",
      "10346\n",
      "('process ...', 19, 43, 200, 232)\n",
      "10614\n",
      "('process ...', 9, 71, 300, 86)\n",
      "9023\n",
      "('process ...', 23, 71, 400, 303)\n",
      "10063\n",
      "('process ...', 33, 37, 500, 411)\n",
      "10797\n",
      "('process ...', 61, 61, 600, 640)\n",
      "10461\n",
      "('process ...', 20.0, 56.0, 0, 241)\n",
      "10322\n",
      "('process ...', 70.0, 74.0, 100, 650)\n",
      "10343\n",
      "('process ...', 62.0, 64.0, 200, 623)\n",
      "10438\n",
      "('process ...', 24.0, 36.0, 300, 286)\n",
      "10821\n",
      "('process ...', 20.0, 40.0, 400, 233)\n",
      "10703\n",
      "('process ...', 22.0, 24.0, 500, 253)\n",
      "11009\n",
      "('process ...', 54.0, 76.0, 600, 591)\n",
      "10354\n",
      "('process ...', 19.5, 63.5, 0, 241)\n",
      "10117\n",
      "('process ...', 39.5, 75.5, 100, 482)\n",
      "10291\n",
      "('process ...', 63.5, 67.5, 200, 628)\n",
      "10410\n",
      "('process ...', 33.5, 41.5, 300, 405)\n",
      "10745\n",
      "('process ...', 5.5, 7.5, 400, 1)\n",
      "11415\n",
      "('process ...', 9.5, 59.5, 500, 84)\n",
      "9539\n",
      "('process ...', 19.5, 29.5, 600, 224)\n",
      "10923\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  I made two train/test datasets with sampling rate 8192/4096:\n",
    "###     bbh_test_xxxx.h5\n",
    "###     bbh_train_xxxx.h5\n",
    "###\n",
    "\n",
    "###  Update: I realized the whiten noise is exactly the Gaussian(0,1), so don't need to prepare it. \n",
    "### \n",
    "###\n",
    "import h5py\n",
    "RATE = 0   ## to be read from data file\n",
    "MERGER_IDX=0.66\n",
    "\n",
    "aligo_psd   = aLIGO_PSD()\n",
    "f_aligo_psd = aligo_psd.sample_frequencies\n",
    "aligo_psd_inp = aLIGO_PSD_inp()\n",
    "\n",
    "def get_whiten_template(h5name, A=1.0):\n",
    "  \n",
    "    HDF5_FILE = h5name\n",
    "    f = h5py.File(HDF5_FILE,'r')\n",
    "\n",
    "    RATE = f[\"/waveform\"].attrs.get('srate')\n",
    "    dt=1.0/RATE\n",
    "    keys = f[\"/waveform\"].keys()\n",
    "    #print(keys)\n",
    "    \n",
    "    co=0\n",
    "    xhc = []\n",
    "    xhp = []\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    n = []\n",
    "    for i in keys:\n",
    "        i = int(i)\n",
    "        key = 'waveform/%d'% i\n",
    "        kp  = 'waveform/%d/hp'%i\n",
    "        kc  = 'waveform/%d/hc'%i\n",
    "    \n",
    "        m1 = f[key].attrs['m'][0]\n",
    "        m2 = f[key].attrs['m'][1]\n",
    "        #s1   = f[key].attrs['sz'][0]\n",
    "        #flow = f[key].attrs['F_low']\n",
    "        midx = f[key].attrs['midx']   # merger idx is usually close to the last array index.\n",
    "        hp  = f[kp][:]\n",
    "        hc  = f[kc][:]\n",
    "\n",
    "        if (co%100==0):  \n",
    "            print (\"process ...\", m1, m2, co, i)\n",
    "            print (midx)\n",
    "        co=co+1\n",
    "    \n",
    "        #leng = len(hp)\n",
    "        #maxh = max(np.abs(hp+hc*1.j))\n",
    "        #print (\"MAX: \", maxh)\n",
    " \n",
    "        ## to slightly move peak randomly, find the starting index in the template\n",
    "        W=RATE*2   ## fix 2-sec strain\n",
    "        merger_idx = W * MERGER_IDX    ###  put merger at 66% position of template\n",
    "        \n",
    "        #idxm = np.where( t2m >= 0 )[0][0]                         ## locate the index of merger time\n",
    "        \n",
    "        y1.append( m1 )\n",
    "        y2.append( m2 )\n",
    "\n",
    "        #==========\n",
    "        #for h in [hp, hc]:   ## generate 2 instances for each data\n",
    "            \n",
    "        #idx0 = int(midx - W * np.random.uniform(0.55, 0.7)  + 1)  \n",
    "        idx0 = int(midx - merger_idx + 1)     #  usually positive\n",
    "        if (idx0<0): idx0 = 0                                    ## if the template is too short, let it be.  \n",
    "\n",
    "        # Generate LIGO noise\n",
    "        #ligo_ns = pycbc.noise.noise_from_psd(W, dt, aLIGO_PSD_imp, seed=None)\n",
    "\n",
    "        # Injected / shifted signal\n",
    "        minidx = min(len(hp)-1, idx0+W)   \n",
    "\n",
    "        shifted_hp = np.zeros(W)   ##ligo_ns.data\n",
    "        shifted_hc = np.zeros(W)   ##ligo_ns.data\n",
    "\n",
    "        shifted_hp[0:minidx-idx0] = shifted_hp[0:minidx-idx0] + hp[idx0:minidx]\n",
    "        shifted_hc[0:minidx-idx0] = shifted_hc[0:minidx-idx0] + hc[idx0:minidx]\n",
    "\n",
    "        whiten_hp = whiten(   shifted_hp, aligo_psd_inp, dt)\n",
    "        whiten_hc = whiten(   shifted_hc, aligo_psd_inp, dt)\n",
    "\n",
    "        tmphp =  whiten_hp[RATE/2:-RATE/2]   ###  keep only 1-sec (8192) data as GWDA dataset\n",
    "        tmphc =  whiten_hc[RATE/2:-RATE/2]\n",
    "\n",
    "        maxf = A * np.sqrt(2*np.log(2.)) / max( np.sqrt(tmphp**2+ tmphc**2)  )\n",
    "        \n",
    "        xhp.append( tmphp * maxf )   ### normalize to the scale of gaussian noise (0,1)\n",
    "        xhc.append( tmphc * maxf )\n",
    "    \n",
    "    f.close()  \n",
    "    return xhp, xhc, y1,y2\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "\n",
    "###################################### Edit here\n",
    "RATE=8192\n",
    "RATE=4096\n",
    "DM=1\n",
    "DM=2\n",
    "#######################################\n",
    "OUTFILE=\"white_h_%d_dm%d.h5\" % (RATE,DM)\n",
    "\n",
    "save = h5.File(OUTFILE, \"w\")  #_small\n",
    "#save.attrs[u'merger_idx'] = MERGER_IDX\n",
    "#save.attrs[u'srate'] = RATE\n",
    "save.attrs.create('srate', RATE, dtype=np.int)\n",
    "save.attrs.create('merger_idx', MERGER_IDX, dtype=np.float)\n",
    "\n",
    "\n",
    "for tag in ['train', 'val', 'test']:\n",
    "    SRC = \"bbh_%d_dm%d_%s.h5\"%(RATE, DM,tag)\n",
    "    xhp, xhc, y1, y2  = get_whiten_template(SRC)   ##0.07\n",
    "\n",
    "    save.create_dataset(\"%s_hp\"%tag,  data=xhp, dtype='f')  # compression='gzip'\n",
    "    save.create_dataset(\"%s_hc\"%tag,  data=xhc, dtype='f')  # compression='gzip'\n",
    "    save.create_dataset(\"%s_m1\"%tag,  data=y1, dtype='f')\n",
    "    save.create_dataset(\"%s_m2\"%tag,  data=y2, dtype='f')\n",
    "\n",
    "save.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
