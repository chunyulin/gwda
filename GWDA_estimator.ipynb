{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lincy/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Not function yet......\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "###\n",
    "###  Prepare data: extract, transform, load (ETL)\n",
    "###\n",
    "import h5py as h5\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "    \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "LABLE_WIDTH = 1\n",
    "DATA_WIDTH  = 8192\n",
    "X_FEATURE = 'x'  # Name of the input feature.\n",
    "\n",
    "RATE = 8192\n",
    "BATCH = 128\n",
    "EPOCHS = 300\n",
    "\n",
    "#FLAGS = tf.app.flags.FLAGS\n",
    "#tf.app.flags.DEFINE_string(\"train_data_path\", \"/home/yongcai/chinese_fenci/train.txt\", \"training data dir\")\n",
    "#tf.app.flags.DEFINE_string(\"log_dir\", \"./logs\", \" the log dir\")\n",
    "#tf.app.flags.DEFINE_integer(\"max_sentence_len\", 80, \"max num of tokens per query\")\n",
    "#tf.app.flags.DEFINE_integer(\"shuffle_buffer_size\", )\n",
    "\n",
    " \n",
    "class GWInject():\n",
    "    def _add_noise(self, tag, A):\n",
    "        var = self.f[tag]\n",
    "        NX = len(var)\n",
    "        X = (A * var[:NX,:] + np.random.normal(0,1,(NX,self.srate))).astype(np.float32)\n",
    "        Y = np.ones(NX)\n",
    "        NN = NX\n",
    "        X  = np.vstack( (X, np.random.normal(0,1,(NN,self.srate)) )  ).astype(np.float32)\n",
    "        Y  = np.hstack( (Y, np.zeros(NN) )                          ).astype(np.float32).reshape(-1,1)\n",
    "        \n",
    "        if 1:\n",
    "            plt.figure(figsize=(15,6))\n",
    "            for i in range(len(X)):\n",
    "                plt.subplot(4,5,i+1)\n",
    "                plt.plot(X[i,:])\n",
    "                plt.plot(A * var[i,:])\n",
    "                #plt.title(\" )\n",
    "                if (i > 18): break\n",
    "            plt.show()\n",
    "\n",
    "        return X, Y\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "        self.f = h5.File(fname, \"r\")\n",
    "        self.srate = self.f.attrs.get('srate')\n",
    "\n",
    "    def __exit__(self):\n",
    "        self.f.close()\n",
    "        \n",
    "    def get_train_val_set(self, A=1.0):\n",
    "        X, Y = self._add_noise('/train', A)\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.25, shuffle=True, random_state=None)\n",
    "        return X_train, X_val, Y_train, Y_val\n",
    "        \n",
    "    def get_test_set(self, A=1.0):\n",
    "        X, Y = self._add_noise('/test', A)\n",
    "        return X,Y\n",
    "        \n",
    "    \n",
    "###  TODO: generate the training set on-the-fly with lamdba mapping  ??    \n",
    "#ds = WaveDS(\"white_h_fixed.h5\", A=1)\n",
    "#ds.plot()\n",
    "\n",
    "#train_ds = ds.train.batch(BATCH)\n",
    "#test_ds  = ds.test.batch(BATCH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### StoppingLossHook\n",
    "#### LoggerHook\n",
    "####\n",
    "class StoppingLossHook(tf.train.SessionRunHook):\n",
    "    def __init__(self, monitor, eps=0.01, patience=5, max=10000):\n",
    "        self.monitor = monitor\n",
    "        self.eps = eps\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "        self.max = max\n",
    "\n",
    "    def begin(self):\n",
    "        # Convert names to tensors if given\n",
    "        graph = tf.get_default_graph()\n",
    "        self.monitor = graph.as_graph_element(self.monitor)\n",
    "        self.iter = 0\n",
    "        if isinstance(self.monitor, tf.Operation):\n",
    "            self.monitor = self.monitor.outputs[0]\n",
    "\n",
    "    def before_run(self, run_context):  # pylint: disable=unused-argument\n",
    "        return tf.train.SessionRunArgs(self.monitor)\n",
    "\n",
    "    def after_run(self, run_context, run_values):\n",
    "        self.iter += 1\n",
    "\n",
    "        if self.iter>self.max: run_context.request_stop()  \n",
    "\n",
    "        if run_values.results > self.eps:\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                run_context.request_stop()  \n",
    "                \n",
    "class LoggerHook(tf.train.SessionRunHook):\n",
    "    def __init__(self, monitor, interval=100):\n",
    "        self.monitor = monitor\n",
    "        self.interval = interval\n",
    "\n",
    "    def begin(self):\n",
    "        self._step = -1\n",
    "        self._start_time = time.time()\n",
    "\n",
    "        # Convert names to tensors if given\n",
    "        graph = tf.get_default_graph()\n",
    "        self.monitor = graph.as_graph_element(self.monitor)\n",
    "        if isinstance(self.monitor, tf.Operation):\n",
    "            self.monitor = self.monitor.outputs[0]\n",
    "\n",
    "    def before_run(self, run_context):\n",
    "        self._step += 1\n",
    "        return tf.train.SessionRunArgs(self.monitor)\n",
    "\n",
    "    def after_run(self, run_context, run_values):\n",
    "        if self._step % self.interval == 0:\n",
    "\n",
    "            res = run_values.results\n",
    "\n",
    "            current_time = time.time()\n",
    "            duration = current_time - self._start_time\n",
    "            self._start_time = current_time\n",
    "\n",
    "            # sample / second\n",
    "            examples_per_sec = self.interval * BATCH / duration\n",
    "            # time / batch\n",
    "            sec_per_batch = float(duration / self.interval)\n",
    "            format_str = ('Step: %4d, loss: %.2g  ( %.1f examples/sec; %.1f sec/batch)')\n",
    "            print(format_str % (self._step, res, examples_per_sec, sec_per_batch))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Prepare NN model\n",
    "###\n",
    "\n",
    "def convl(in_, F, K, D, S, PO, PS, act):\n",
    "    args = {\"padding\":'valid', \"activation\":None, \n",
    "        \"kernel_initializer\":tf.truncated_normal_initializer(), \n",
    "        \"bias_initializer\":tf.zeros_initializer()     }\n",
    "    out = tf.layers.conv1d( in_, filters=F, kernel_size=K, dilation_rate=D, strides=S, **args)\n",
    "    out = tf.layers.max_pooling1d(out, pool_size=PO, strides=PS, padding='valid')\n",
    "    return act(out)\n",
    "\n",
    "def conv_model_hi(x_):\n",
    "    feature = tf.reshape(x_, [-1, DATA_WIDTH,1])\n",
    "    c1 = convl(feature, F= 64, K=16, D=1, S=1, PO=4, PS=4, act=tf.nn.relu)\n",
    "    c2 = convl(c1,      F=128, K=16, D=2, S=1, PO=4, PS=4, act=tf.nn.relu)\n",
    "    c3 = convl(c2,      F=256, K=16, D=2, S=1, PO=4, PS=4, act=tf.nn.relu)\n",
    "    c4 = convl(c3,      F=512, K=32, D=2, S=1, PO=4, PS=4, act=tf.nn.relu)\n",
    "\n",
    "    dim = c4.get_shape().as_list()\n",
    "    fcnn = dim[1]*dim[2]\n",
    "    l1 = tf.reshape(c4, [-1, fcnn])\n",
    "    \n",
    "    l2     = tf.layers.dense(l1, 128, activation=tf.nn.relu)\n",
    "    l3     = tf.layers.dense(l2,  64, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(l3,   1, activation=None)\n",
    "    return logits\n",
    "\n",
    "def conv_model_low(x_):\n",
    "    feature = tf.reshape(x_, [-1, DATA_WIDTH,1])\n",
    "\n",
    "    o1 = convl(feature, F=16, K=16, D=1, S=1, PO=4, PS=4, act=tf.nn.relu)\n",
    "    o2 = convl(o1,      F=32, K=8,  D=4, S=1, PO=4, PS=4, act=tf.nn.relu)\n",
    "    o3 = convl(o2,      F=64, K=8,  D=4, S=1, PO=4, PS=4, act=tf.nn.relu)\n",
    "    \n",
    "    dim = o3.get_shape().as_list()\n",
    "    fcnn = dim[1]*dim[2]\n",
    "    l1 = tf.reshape(o3, [-1, fcnn])\n",
    "    # Densely connected layer\n",
    "    l2     = tf.layers.dense(l1, 64, activation=tf.nn.relu, name=\"dense_layer\")\n",
    "    logits = tf.layers.dense(l2,  1, activation=None, name=\"logit\")\n",
    "    return logits\n",
    "\n",
    "    \n",
    "def model(x_, labels, mode):\n",
    "\n",
    "    #logits = conv_model_low(x_)\n",
    "    logits = conv_model_hi(x_)\n",
    "    \n",
    "    # Compute predictions\n",
    "    predict_prob = tf.sigmoid(logits, name=\"sigmoid_tensor\")\n",
    "    predict_op   = tf.round(predict_prob)  ## return largest index   ##tf.cast( tf.round(predict_prob), tf.int32 )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class': predict_op,\n",
    "            'prob': predict_prob\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Create training op.\n",
    "    loss_op = tf.losses.sigmoid_cross_entropy(logits=logits, multi_class_labels=labels)\n",
    "    #print (\"================ loss: \", mode, loss.get_shape())\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #learning_rate = tf.train.exponential_decay(0.05, tf.train.get_global_step(), decay_steps=2000, decay_rate=0.95, staircase=True)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "        #optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "        train_op  = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "        #logger_hook    = LoggerHook(monitor=loss,          interval=50)\n",
    "        #logger_hook2   = LoggerHook(monitor=learning_rate, interval=100)\n",
    "        stopping_hook = StoppingLossHook(monitor=loss, eps=1e-2, max=9999)\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op, training_hooks=[stopping_hook])\n",
    "\n",
    "    # Compute evaluation metrics.\n",
    "    eval_metric_ops = {\n",
    "        #'accuracy':  tf.losses.sigmoid_cross_entropy(logits=logits, multi_class_labels=labels)\n",
    "        'accuracy':    tf.metrics.accuracy(labels=labels, predictions=predict_op  ),\n",
    "        'sensitivity': tf.metrics.recall(labels=labels, predictions=predict_op  )\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 119, 64]\n",
      "Saving graph to: /tmp/tf_tmp\n",
      "<tf.Variable 'conv1d/kernel:0' shape=(16, 1, 16) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d/bias:0' shape=(16,) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_1/kernel:0' shape=(8, 16, 32) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_1/bias:0' shape=(32,) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_2/kernel:0' shape=(8, 32, 64) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_2/bias:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_layer/kernel:0' shape=(7616, 64) dtype=float32_ref>\n",
      "<tf.Variable 'dense_layer/bias:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'logit/kernel:0' shape=(64, 1) dtype=float32_ref>\n",
      "<tf.Variable 'logit/bias:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'adam_optimizer/beta1_power:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'adam_optimizer/beta2_power:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'conv1d/kernel/Adam:0' shape=(16, 1, 16) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d/kernel/Adam_1:0' shape=(16, 1, 16) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d/bias/Adam:0' shape=(16,) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d/bias/Adam_1:0' shape=(16,) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_1/kernel/Adam:0' shape=(8, 16, 32) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_1/kernel/Adam_1:0' shape=(8, 16, 32) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_1/bias/Adam:0' shape=(32,) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_2/kernel/Adam:0' shape=(8, 32, 64) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_2/kernel/Adam_1:0' shape=(8, 32, 64) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_2/bias/Adam:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_2/bias/Adam_1:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_layer/kernel/Adam:0' shape=(7616, 64) dtype=float32_ref>\n",
      "<tf.Variable 'dense_layer/kernel/Adam_1:0' shape=(7616, 64) dtype=float32_ref>\n",
      "<tf.Variable 'dense_layer/bias/Adam:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_layer/bias/Adam_1:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'logit/kernel/Adam:0' shape=(64, 1) dtype=float32_ref>\n",
      "<tf.Variable 'logit/kernel/Adam_1:0' shape=(64, 1) dtype=float32_ref>\n",
      "<tf.Variable 'logit/bias/Adam:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'logit/bias/Adam_1:0' shape=(1,) dtype=float32_ref>\n",
      "Whole size: 11.636 MB | Var # : 32\n",
      "<tf.Variable 'conv1d/kernel:0' shape=(16, 1, 16) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d/bias:0' shape=(16,) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_1/kernel:0' shape=(8, 16, 32) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_1/bias:0' shape=(32,) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_2/kernel:0' shape=(8, 32, 64) dtype=float32_ref>\n",
      "<tf.Variable 'conv1d_2/bias:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_layer/kernel:0' shape=(7616, 64) dtype=float32_ref>\n",
      "<tf.Variable 'dense_layer/bias:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'logit/kernel:0' shape=(64, 1) dtype=float32_ref>\n",
      "<tf.Variable 'logit/bias:0' shape=(1,) dtype=float32_ref>\n",
      "Model size: 3.879 MB | Var # : 10\n",
      "<tf.Variable 'accuracy/total:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'accuracy/count:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'recall/true_positives/count:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'recall/false_negatives/count:0' shape=() dtype=float32_ref>\n",
      "Local var size: 32.000 Bytes | Var # : 4\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Construct TF graph\n",
    "###\n",
    "tf.reset_default_graph()\n",
    "DIM = 8192\n",
    "keep_prob = tf.placeholder(tf.float32)  ##  for dropout\n",
    "bs        = tf.placeholder(tf.int64)    ##  for initalizer\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None,DIM])\n",
    "y = tf.placeholder(tf.float32, [None,1])\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(buffer_size=10*bs).batch(bs).repeat()\n",
    "test_ds  = tf.data.Dataset.from_tensor_slices((x, y)).batch(bs)\n",
    "\n",
    "## Use two iterators\n",
    "#train_iter = train_ds.make_initializable_iterator()  ## \n",
    "#test_iter  = test_ds.make_initializable_iterator()   ## no shuffle/repeat\n",
    "\n",
    "## Use one common iterator\n",
    "iter = tf.data.Iterator.from_structure(train_ds.output_types, train_ds.output_shapes)\n",
    "features, labels = iter.get_next()\n",
    "\n",
    "# create the initialisation operations\n",
    "train_init_op = iter.make_initializer(train_ds)\n",
    "test_init_op = iter.make_initializer(test_ds)\n",
    "\n",
    "#graph_location = '/tmp/tf_tmp'\n",
    "#merged = tf.summary.merge_all()\n",
    "#print('Saving graph to: %s' % graph_location)\n",
    "\n",
    "### check all variables\n",
    "if 1:\n",
    "    vars = 0\n",
    "    for v in tf.global_variables():\n",
    "        print (v)\n",
    "        vars += np.prod(v.get_shape().as_list())\n",
    "    print(\"Whole size: %.3f MB | Var # : %d\" % (8*vars/(1024**2), len(tf.global_variables()) ) )\n",
    "\n",
    "    vars = 0\n",
    "    for v in tf.trainable_variables():\n",
    "        print (v)\n",
    "        vars += np.prod(v.get_shape().as_list())\n",
    "    print(\"Model size: %.3f MB | Var # : %d\" % (8*vars/(1024**2), len(tf.trainable_variables()) ) )\n",
    "\n",
    "    vars = 0\n",
    "    for v in tf.local_variables():\n",
    "        print (v)\n",
    "        vars += np.prod(v.get_shape().as_list())\n",
    "    print(\"Local var size: %.3f Bytes | Var # : %d\" % (8*vars, len(tf.local_variables()) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7740, 8192)\n",
      "(2580, 8192)\n",
      "(7740, 1)\n",
      "(2580, 1)\n",
      "Test set size: 315.375 MBytes\n",
      "step:     0, loss:    5.8e+02 accuracy:       0.52\n",
      "Test Loss: 56 Acc: 0.469\n",
      "Test Loss: 88 Acc: 0.414\n",
      "Test Loss: 55 Acc: 0.426\n",
      "Test Loss: 74 Acc: 0.412\n",
      "Test Loss: 84 Acc: 0.397\n",
      "Test Loss: 70 Acc: 0.401\n",
      "Test Loss: 61 Acc: 0.402\n",
      "Test Loss: 69 Acc: 0.398\n",
      "Test Loss: 55 Acc: 0.404\n",
      "Test Loss: 75 Acc: 0.398\n",
      "Test Loss: 67 Acc: 0.400\n",
      "Test Loss: 71 Acc: 0.401\n",
      "Test Loss: 64 Acc: 0.398\n",
      "Test Loss: 60 Acc: 0.398\n",
      "Test Loss: 65 Acc: 0.399\n",
      "Test Loss: 63 Acc: 0.403\n",
      "Test Loss: 59 Acc: 0.405\n",
      "Test Loss: 72 Acc: 0.405\n",
      "Test Loss: 64 Acc: 0.406\n",
      "Test Loss: 57 Acc: 0.407\n",
      "Test Loss: 68 Acc: 0.406\n",
      "Test Loss: 72 Acc: 0.403\n",
      "Test Loss: 68 Acc: 0.401\n",
      "Test Loss: 69 Acc: 0.401\n",
      "Test Loss: 83 Acc: 0.396\n",
      "Test Loss: 54 Acc: 0.398\n",
      "Test Loss: 55 Acc: 0.402\n",
      "Test Loss: 67 Acc: 0.403\n",
      "Test Loss: 68 Acc: 0.402\n",
      "Test Loss: 67 Acc: 0.401\n",
      "Test Loss: 66 Acc: 0.402\n",
      "Test Loss: 67 Acc: 0.402\n",
      "Test Loss: 73 Acc: 0.401\n",
      "Test Loss: 68 Acc: 0.400\n",
      "Test Loss: 68 Acc: 0.400\n",
      "Test Loss: 65 Acc: 0.399\n",
      "Test Loss: 61 Acc: 0.399\n",
      "Test Loss: 72 Acc: 0.399\n",
      "Test Loss: 67 Acc: 0.399\n",
      "Test Loss: 28 Acc: 0.406\n",
      "Test Loss: 12 Acc: 0.416\n",
      "Test Loss: 14 Acc: 0.425\n",
      "Test Loss: 16 Acc: 0.434\n",
      "Test Loss: 10 Acc: 0.442\n",
      "Test Loss: 11 Acc: 0.451\n",
      "Test Loss: 14 Acc: 0.460\n",
      "Test Loss: 9 Acc: 0.468\n",
      "Test Loss: 10 Acc: 0.475\n",
      "Test Loss: 8 Acc: 0.483\n",
      "Test Loss: 14 Acc: 0.489\n",
      "Test Loss: 12 Acc: 0.496\n",
      "Test Loss: 9 Acc: 0.502\n",
      "Test Loss: 10 Acc: 0.508\n",
      "Test Loss: 9 Acc: 0.514\n",
      "Test Loss: 13 Acc: 0.520\n",
      "Test Loss: 9 Acc: 0.526\n",
      "Test Loss: 10 Acc: 0.532\n",
      "Test Loss: 15 Acc: 0.536\n",
      "Test Loss: 16 Acc: 0.541\n",
      "Test Loss: 10 Acc: 0.546\n",
      "Test Loss: 12 Acc: 0.550\n",
      "Test Loss: 10 Acc: 0.554\n",
      "Test Loss: 12 Acc: 0.557\n",
      "Test Loss: 13 Acc: 0.561\n",
      "Test Loss: 7 Acc: 0.566\n",
      "Test Loss: 9 Acc: 0.570\n",
      "Test Loss: 13 Acc: 0.573\n",
      "Test Loss: 14 Acc: 0.577\n",
      "Test Loss: 15 Acc: 0.579\n",
      "Test Loss: 6 Acc: 0.583\n",
      "Test Loss: 12 Acc: 0.586\n",
      "Test Loss: 5 Acc: 0.590\n",
      "Test Loss: 11 Acc: 0.593\n",
      "Test Loss: 11 Acc: 0.596\n",
      "Test Loss: 10 Acc: 0.599\n",
      "Test Loss: 10 Acc: 0.602\n",
      "Test Loss: 9 Acc: 0.606\n",
      "Test Loss: 11 Acc: 0.609\n",
      "Test Loss: 17 Acc: 0.610\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "End of sequence\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,8192], [?,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\t [[Node: IteratorGetNext/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_85_IteratorGetNext\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op u'IteratorGetNext', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/lib64/python2.7/site-packages/tornado/ioloop.py\", line 1065, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-677b2d128e86>\", line 21, in <module>\n    features, labels = iter.get_next()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 330, in get_next\n    name=name)), self._output_types,\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 866, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,8192], [?,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\t [[Node: IteratorGetNext/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_85_IteratorGetNext\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8ac90b71e194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_init_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mXts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mYts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mBATCH\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredict_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Loss: %.f Acc: %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,8192], [?,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\t [[Node: IteratorGetNext/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_85_IteratorGetNext\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op u'IteratorGetNext', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/lib64/python2.7/site-packages/tornado/ioloop.py\", line 1065, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-677b2d128e86>\", line 21, in <module>\n    features, labels = iter.get_next()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 330, in get_next\n    name=name)), self._output_types,\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 866, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,8192], [?,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\t [[Node: IteratorGetNext/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_85_IteratorGetNext\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "##  Use Numpy matrix\n",
    "##\n",
    "STEPS=100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #train_writer = tf.summary.FileWriter(graph_location + '/train', sess.graph)\n",
    "    #train_writer.add_graph(tf.get_default_graph())\n",
    "    #test_writer  = tf.summary.FileWriter(graph_location + '/test')\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(train_init_op, feed_dict={ x:Xt, y:Yt, bs:BATCH})   ##, batch_size: BATCH\n",
    "    \n",
    "    for i in range(STEPS):\n",
    "        optimizer.run()\n",
    "        if i % 100 == 0:\n",
    "            _, loss, acc = sess.run( [optimizer, loss_op, accuracy] )   ## \n",
    "            print('step: %5d, loss: %10.2g accuracy: %10.2g' % (i, loss, acc))\n",
    "\n",
    "    # test model\n",
    "    sess.run(test_init_op, feed_dict={ x: Xts, y: Yts, bs:BATCH })\n",
    "    for i in range(int(len(Xts)/BATCH)+2):\n",
    "        pre, loss, acc = sess.run([predict_prob, loss_op, accuracy])\n",
    "        print(\"Test Loss: %.f Acc: %.3f\" % (loss, acc) )\n",
    "    \n",
    "\n",
    "    \n",
    "def train_input_fn():\n",
    "    \"\"\"\n",
    "    return training set (x,y)\n",
    "    \"\"\"\n",
    "    ds = tf.data.TFRecordDataset(FLAGS.train_dataset)\n",
    "    train_dataset = train_dataset.map(parser)\n",
    "    # num_epochs 为整个数据集的迭代次数\n",
    "    train_dataset = train_dataset.repeat(FLAGS.num_epochs)\n",
    "    train_dataset = train_dataset.batch(FLAGS.batch_size)\n",
    "    train_iterator = train_dataset.make_one_shot_iterator()\n",
    "\n",
    "    features, labels = train_iterator.get_next()\n",
    "    return features, labels\n",
    "    \n",
    "    \n",
    "def CNN(A):\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)   ### WARN\n",
    "       \n",
    "    GWdata = GWInject(\"white_h_fixed.h5\")\n",
    "    X_train, X_val, y_train, y_val = GWdata.get_train_val_set(A)\n",
    "    X_test , Y_test                = GWdata.get_test_set(A)\n",
    "    print(\"Test set size: %.3f MBytes\" % (np.prod(np.shape(Xts))*4/1024**2 ) )\n",
    "    \n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = { X_FEATURE: X_train },  y = y_train,\n",
    "        batch_size = BATCH,  ### step = N / Batch * epoches\n",
    "        num_epochs = EPOCHS,  shuffle=True)\n",
    "    test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = { X_FEATURE: X_test },   y= y_test,\n",
    "        #batch_size = None,\n",
    "        num_epochs=1,   shuffle=False)\n",
    "\n",
    "    ########## CNN\n",
    "    #try: os.remove('/tmp/tf_lin/checkpoint')  \n",
    "    #except OSError: pass\n",
    "\n",
    "    config = tf.contrib.learn.RunConfig(\n",
    "        save_checkpoints_steps=10000000000,  ## at 1 and last\n",
    "        save_checkpoints_secs=None,\n",
    "        save_summary_steps=None,\n",
    "        #gpu_memory_fraction=0.5,\n",
    "        model_dir='/tmp/tf_lin'\n",
    "    )\n",
    "    classifier = tf.estimator.Estimator(model_fn=conv_model, config=config)\n",
    "    \n",
    "    classifier.train(input_fn=train_input_fn, steps=None)\n",
    "    #classifier.export_savedmodel('/tmp/tf_lin/saved', serving_input_receiver_fn=train_input_fn, strip_default_attrs=True)\n",
    "    \n",
    "    \n",
    "    scores = classifier.evaluate(input_fn=test_input_fn, steps=None)\n",
    "    \n",
    "\n",
    "\n",
    "    if 0:  \n",
    "        ######### Linear classifier.\n",
    "        feature_columns = [ tf.feature_column.numeric_column(X_FEATURE, shape=RATE) ]\n",
    "\n",
    "        classifier = tf.estimator.LinearClassifier(feature_columns = feature_columns, n_classes=LABLE_WIDTH)\n",
    "        classifier.train(input_fn=train_input_fn, steps=None)\n",
    "        scores = classifier.evaluate(input_fn=test_input_fn, steps=None)\n",
    "        print(\"+++++ LC: \", scores)\n",
    "\n",
    "    \n",
    "gloss = []\n",
    "gacc  = []\n",
    "gsen  = []\n",
    "gstep = []\n",
    "def main(unused):\n",
    "    try: os.remove('/tmp/tf_gwda/checkpoint')  \n",
    "    except OSError: pass\n",
    "\n",
    "    #saver = tf.train.Saver()\n",
    "    #snr = [0.075,0.05,0.025, 0.02, 0.01, 0.005, 0.003, 0.002, 0.001,  0.0001]\n",
    "    snr = [1.0, 0.8, 0.6, 0.4, 0.3, 0.2,0.1, 0.05]\n",
    "    for i in snr:\n",
    "        l, a, s = CNN(i)\n",
    "        gloss.append(l)\n",
    "        gacc.append(a)\n",
    "        gsen.append(s)\n",
    "        gstep.append(tf.train.get_global_step())\n",
    "    print(\"Loss  :\", gloss)\n",
    "    print(\"Acc   :\", gacc)\n",
    "    print(\"Recall:\", gsen)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
